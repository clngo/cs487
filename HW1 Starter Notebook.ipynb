{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code used to run the analysis is located in the online repository here:\n",
    "https://github.com/jonathanventura/canopy\n",
    "Files needed:Hyperspectral Imagery: data/NEON_D17_TEAK_DP1_20170627_181333_reflectance.tif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "5OUW75f1w56j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CNAG8fBHw_ns"
   },
   "outputs": [],
   "source": [
    "#  Not needed as I have the actual file locally because this code wasn't working for me :/\n",
    "# if not os.path.exists('tree_species_classifier_data.npz'):\n",
    "#   !wget -O tree_species_classifier_data.npz \"https://www.dropbox.com/scl/fi/b7mw23k3ifaeui9m8nnn3/tree_species_classifier_data.npz?rlkey=bgxp37c1t04i7q35waf3slc26&dl=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "XSnb9owtxT5w"
   },
   "outputs": [],
   "source": [
    "data = np.load('tree_species_classifier_data.npz')\n",
    "train_features = data['train_features']\n",
    "train_labels = data['train_labels']\n",
    "test_features = data['test_features']\n",
    "test_labels = data['test_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Preprocess the data with PCA\n",
    "train_labels = torch.tensor(train_labels).long()\n",
    "test_labels = torch.tensor(test_labels).long()\n",
    "\n",
    "# Fit the PCA model using 32 components and whiten = True from the instructions\n",
    "pca = sklearn.decomposition.PCA(n_components=32, whiten=True)\n",
    "pca_train_features = torch.tensor(pca.fit_transform(train_features)).float()\n",
    "pca_test_features = torch.tensor(pca.transform(test_features)).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca_train_features shape: torch.Size([15707, 32])\n",
      "train_labels shape: torch.Size([15707])\n"
     ]
    }
   ],
   "source": [
    "print(f\"pca_train_features shape: {pca_train_features.shape}\")\n",
    "print(f\"train_labels shape: {train_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Classifiers using scikit-learn\n",
    "\n",
    "linear_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32, len(np.unique(train_labels))), # 32 inputs, number of train_label outputs\n",
    ")\n",
    "# Like in Lab 3.1, use Multi-Layer Perceptron (MLP) to implement all 100 hidden layers. \n",
    "mlp_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(32, 100), # 32 inputs, 1 hidden layer of size 100\n",
    "    \n",
    "    # hidden activation function, the magic happens\n",
    "    torch.nn.ReLU(),\n",
    "    \n",
    "    # 100 inputs, number of train_label outputs\n",
    "    torch.nn.Linear(100, len(np.unique(train_labels))) \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-entropy loss function and a stochastic gradient descent (SGD) optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "lr = 1e-2\n",
    "linear_opt = torch.optim.SGD(linear_model.parameters(), lr=lr, weight_decay=0.001)\n",
    "mlp_opt = torch.optim.SGD(mlp_model.parameters(), lr=lr, weight_decay=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classifier Accuracy 0.8275418275418276\n",
      "MLP Classifier Accuracy 0.859073359073359\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Classifiers using scikit-learn. Make a linear classifier and a neural network (NN)\n",
    "classifier using scikit-learn and calculate accuracy on the test set for each\n",
    "classifier. The N should have three layers and a hidden layer size of 100.\n",
    "\"\"\"\n",
    "def accuracy(model, X, y):\n",
    "    \n",
    "    # Set model to evaluation mode \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model(X)\n",
    "        \n",
    "        # First dimension of outputs are the samples (dim = 0)\n",
    "        # Second dimension of outputs are the labels (dim = 1)\n",
    "        # Get the highest predicted labels value for each sample in the \n",
    "        sample, predicted_labels = torch.max(z, dim=1)\n",
    "\n",
    "\n",
    "        # Calculate the accuracy (the number of correct predictions divided by total number of samples)\n",
    "        correct = (predicted_labels == y).sum().item()\n",
    "\n",
    "        # size(0) refers to first dimension, which are the samples (dim = 0)\n",
    "        total = y.size(0)\n",
    "\n",
    "        return correct/total\n",
    "\n",
    "print(f\"Linear Classifier Accuracy {accuracy(linear_model, pca_test_features, test_labels)}\")\n",
    "print(f\"MLP Classifier Accuracy {accuracy(mlp_model, pca_test_features, test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Classifiers using PyTorch\n",
    "\n",
    "# a. Create TensorDataset and DataLoader to train and test splits\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(pca_train_features, train_labels)\n",
    "test_dataset = torch.utils.data.TensorDataset(pca_test_features, test_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. calculate model accuracy with data loader\n",
    "def accuracy(model, dataloader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in dataloader:\n",
    "            z = model(batch_X)\n",
    "            sample, predicted_labels = torch.max(z, dim=1)\n",
    "            correct += (predicted_labels == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "\n",
    "    return correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Function to train model\n",
    "\n",
    "def trainModel(model, train_loader, opt, loss_fn):\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            opt.zero_grad()  # Zero out gradients\n",
    "\n",
    "            z = model(batch_X)  # Forward pass\n",
    "            loss = loss_fn(z, batch_y)  # Compute loss\n",
    "\n",
    "            loss.backward()  # Backpropagation\n",
    "            opt.step()  # Apply gradients\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        train_accuracy = accuracy(model, train_loader)\n",
    "        test_accuracy = accuracy(model, test_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.4570, Train Accuracy: 0.7657, Test Accuracy: 0.7445\n",
      "Epoch 2/100, Loss: 0.9524, Train Accuracy: 0.7966, Test Accuracy: 0.7857\n",
      "Epoch 3/100, Loss: 0.8082, Train Accuracy: 0.8088, Test Accuracy: 0.7941\n",
      "Epoch 4/100, Loss: 0.7415, Train Accuracy: 0.8180, Test Accuracy: 0.7992\n",
      "Epoch 5/100, Loss: 0.7026, Train Accuracy: 0.8230, Test Accuracy: 0.8063\n",
      "Epoch 6/100, Loss: 0.6769, Train Accuracy: 0.8266, Test Accuracy: 0.8076\n",
      "Epoch 7/100, Loss: 0.6583, Train Accuracy: 0.8297, Test Accuracy: 0.8082\n",
      "Epoch 8/100, Loss: 0.6444, Train Accuracy: 0.8319, Test Accuracy: 0.8121\n",
      "Epoch 9/100, Loss: 0.6336, Train Accuracy: 0.8331, Test Accuracy: 0.8115\n",
      "Epoch 10/100, Loss: 0.6248, Train Accuracy: 0.8343, Test Accuracy: 0.8140\n",
      "Epoch 11/100, Loss: 0.6174, Train Accuracy: 0.8354, Test Accuracy: 0.8172\n",
      "Epoch 12/100, Loss: 0.6114, Train Accuracy: 0.8363, Test Accuracy: 0.8179\n",
      "Epoch 13/100, Loss: 0.6062, Train Accuracy: 0.8369, Test Accuracy: 0.8160\n",
      "Epoch 14/100, Loss: 0.6016, Train Accuracy: 0.8373, Test Accuracy: 0.8179\n",
      "Epoch 15/100, Loss: 0.5977, Train Accuracy: 0.8385, Test Accuracy: 0.8179\n",
      "Epoch 16/100, Loss: 0.5942, Train Accuracy: 0.8387, Test Accuracy: 0.8179\n",
      "Epoch 17/100, Loss: 0.5910, Train Accuracy: 0.8389, Test Accuracy: 0.8192\n",
      "Epoch 18/100, Loss: 0.5884, Train Accuracy: 0.8398, Test Accuracy: 0.8192\n",
      "Epoch 19/100, Loss: 0.5858, Train Accuracy: 0.8406, Test Accuracy: 0.8224\n",
      "Epoch 20/100, Loss: 0.5835, Train Accuracy: 0.8408, Test Accuracy: 0.8230\n",
      "Epoch 21/100, Loss: 0.5814, Train Accuracy: 0.8411, Test Accuracy: 0.8243\n",
      "Epoch 22/100, Loss: 0.5795, Train Accuracy: 0.8413, Test Accuracy: 0.8237\n",
      "Epoch 23/100, Loss: 0.5778, Train Accuracy: 0.8419, Test Accuracy: 0.8243\n",
      "Epoch 24/100, Loss: 0.5763, Train Accuracy: 0.8424, Test Accuracy: 0.8256\n",
      "Epoch 25/100, Loss: 0.5748, Train Accuracy: 0.8433, Test Accuracy: 0.8263\n",
      "Epoch 26/100, Loss: 0.5734, Train Accuracy: 0.8437, Test Accuracy: 0.8269\n",
      "Epoch 27/100, Loss: 0.5721, Train Accuracy: 0.8438, Test Accuracy: 0.8263\n",
      "Epoch 28/100, Loss: 0.5711, Train Accuracy: 0.8440, Test Accuracy: 0.8275\n",
      "Epoch 29/100, Loss: 0.5700, Train Accuracy: 0.8443, Test Accuracy: 0.8288\n",
      "Epoch 30/100, Loss: 0.5688, Train Accuracy: 0.8443, Test Accuracy: 0.8288\n",
      "Epoch 31/100, Loss: 0.5678, Train Accuracy: 0.8446, Test Accuracy: 0.8269\n",
      "Epoch 32/100, Loss: 0.5671, Train Accuracy: 0.8446, Test Accuracy: 0.8256\n",
      "Epoch 33/100, Loss: 0.5661, Train Accuracy: 0.8447, Test Accuracy: 0.8250\n",
      "Epoch 34/100, Loss: 0.5652, Train Accuracy: 0.8449, Test Accuracy: 0.8250\n",
      "Epoch 35/100, Loss: 0.5644, Train Accuracy: 0.8453, Test Accuracy: 0.8263\n",
      "Epoch 36/100, Loss: 0.5637, Train Accuracy: 0.8452, Test Accuracy: 0.8263\n",
      "Epoch 37/100, Loss: 0.5631, Train Accuracy: 0.8453, Test Accuracy: 0.8256\n",
      "Epoch 38/100, Loss: 0.5625, Train Accuracy: 0.8453, Test Accuracy: 0.8256\n",
      "Epoch 39/100, Loss: 0.5618, Train Accuracy: 0.8457, Test Accuracy: 0.8263\n",
      "Epoch 40/100, Loss: 0.5612, Train Accuracy: 0.8455, Test Accuracy: 0.8243\n",
      "Epoch 41/100, Loss: 0.5607, Train Accuracy: 0.8455, Test Accuracy: 0.8243\n",
      "Epoch 42/100, Loss: 0.5601, Train Accuracy: 0.8458, Test Accuracy: 0.8243\n",
      "Epoch 43/100, Loss: 0.5596, Train Accuracy: 0.8459, Test Accuracy: 0.8243\n",
      "Epoch 44/100, Loss: 0.5590, Train Accuracy: 0.8461, Test Accuracy: 0.8256\n",
      "Epoch 45/100, Loss: 0.5587, Train Accuracy: 0.8464, Test Accuracy: 0.8250\n",
      "Epoch 46/100, Loss: 0.5582, Train Accuracy: 0.8464, Test Accuracy: 0.8256\n",
      "Epoch 47/100, Loss: 0.5578, Train Accuracy: 0.8464, Test Accuracy: 0.8269\n",
      "Epoch 48/100, Loss: 0.5573, Train Accuracy: 0.8465, Test Accuracy: 0.8275\n",
      "Epoch 49/100, Loss: 0.5569, Train Accuracy: 0.8466, Test Accuracy: 0.8243\n",
      "Epoch 50/100, Loss: 0.5566, Train Accuracy: 0.8466, Test Accuracy: 0.8237\n",
      "Epoch 51/100, Loss: 0.5562, Train Accuracy: 0.8466, Test Accuracy: 0.8263\n",
      "Epoch 52/100, Loss: 0.5560, Train Accuracy: 0.8469, Test Accuracy: 0.8263\n",
      "Epoch 53/100, Loss: 0.5555, Train Accuracy: 0.8468, Test Accuracy: 0.8269\n",
      "Epoch 54/100, Loss: 0.5551, Train Accuracy: 0.8469, Test Accuracy: 0.8269\n",
      "Epoch 55/100, Loss: 0.5549, Train Accuracy: 0.8469, Test Accuracy: 0.8269\n",
      "Epoch 56/100, Loss: 0.5546, Train Accuracy: 0.8472, Test Accuracy: 0.8269\n",
      "Epoch 57/100, Loss: 0.5543, Train Accuracy: 0.8467, Test Accuracy: 0.8263\n",
      "Epoch 58/100, Loss: 0.5541, Train Accuracy: 0.8466, Test Accuracy: 0.8256\n",
      "Epoch 59/100, Loss: 0.5537, Train Accuracy: 0.8469, Test Accuracy: 0.8256\n",
      "Epoch 60/100, Loss: 0.5535, Train Accuracy: 0.8471, Test Accuracy: 0.8263\n",
      "Epoch 61/100, Loss: 0.5533, Train Accuracy: 0.8473, Test Accuracy: 0.8269\n",
      "Epoch 62/100, Loss: 0.5530, Train Accuracy: 0.8474, Test Accuracy: 0.8275\n",
      "Epoch 63/100, Loss: 0.5528, Train Accuracy: 0.8471, Test Accuracy: 0.8263\n",
      "Epoch 64/100, Loss: 0.5527, Train Accuracy: 0.8473, Test Accuracy: 0.8263\n",
      "Epoch 65/100, Loss: 0.5523, Train Accuracy: 0.8473, Test Accuracy: 0.8263\n",
      "Epoch 66/100, Loss: 0.5522, Train Accuracy: 0.8480, Test Accuracy: 0.8256\n",
      "Epoch 67/100, Loss: 0.5519, Train Accuracy: 0.8479, Test Accuracy: 0.8256\n",
      "Epoch 68/100, Loss: 0.5517, Train Accuracy: 0.8478, Test Accuracy: 0.8256\n",
      "Epoch 69/100, Loss: 0.5515, Train Accuracy: 0.8479, Test Accuracy: 0.8263\n",
      "Epoch 70/100, Loss: 0.5516, Train Accuracy: 0.8479, Test Accuracy: 0.8256\n",
      "Epoch 71/100, Loss: 0.5513, Train Accuracy: 0.8475, Test Accuracy: 0.8263\n",
      "Epoch 72/100, Loss: 0.5511, Train Accuracy: 0.8475, Test Accuracy: 0.8269\n",
      "Epoch 73/100, Loss: 0.5508, Train Accuracy: 0.8476, Test Accuracy: 0.8256\n",
      "Epoch 74/100, Loss: 0.5506, Train Accuracy: 0.8475, Test Accuracy: 0.8269\n",
      "Epoch 75/100, Loss: 0.5506, Train Accuracy: 0.8476, Test Accuracy: 0.8256\n",
      "Epoch 76/100, Loss: 0.5504, Train Accuracy: 0.8480, Test Accuracy: 0.8256\n",
      "Epoch 77/100, Loss: 0.5503, Train Accuracy: 0.8478, Test Accuracy: 0.8250\n",
      "Epoch 78/100, Loss: 0.5500, Train Accuracy: 0.8475, Test Accuracy: 0.8269\n",
      "Epoch 79/100, Loss: 0.5499, Train Accuracy: 0.8478, Test Accuracy: 0.8263\n",
      "Epoch 80/100, Loss: 0.5498, Train Accuracy: 0.8478, Test Accuracy: 0.8269\n",
      "Epoch 81/100, Loss: 0.5496, Train Accuracy: 0.8480, Test Accuracy: 0.8288\n",
      "Epoch 82/100, Loss: 0.5495, Train Accuracy: 0.8478, Test Accuracy: 0.8282\n",
      "Epoch 83/100, Loss: 0.5493, Train Accuracy: 0.8476, Test Accuracy: 0.8269\n",
      "Epoch 84/100, Loss: 0.5492, Train Accuracy: 0.8479, Test Accuracy: 0.8269\n",
      "Epoch 85/100, Loss: 0.5491, Train Accuracy: 0.8478, Test Accuracy: 0.8269\n",
      "Epoch 86/100, Loss: 0.5490, Train Accuracy: 0.8482, Test Accuracy: 0.8263\n",
      "Epoch 87/100, Loss: 0.5491, Train Accuracy: 0.8484, Test Accuracy: 0.8256\n",
      "Epoch 88/100, Loss: 0.5489, Train Accuracy: 0.8481, Test Accuracy: 0.8263\n",
      "Epoch 89/100, Loss: 0.5486, Train Accuracy: 0.8480, Test Accuracy: 0.8263\n",
      "Epoch 90/100, Loss: 0.5486, Train Accuracy: 0.8482, Test Accuracy: 0.8263\n",
      "Epoch 91/100, Loss: 0.5486, Train Accuracy: 0.8480, Test Accuracy: 0.8269\n",
      "Epoch 92/100, Loss: 0.5483, Train Accuracy: 0.8480, Test Accuracy: 0.8269\n",
      "Epoch 93/100, Loss: 0.5482, Train Accuracy: 0.8485, Test Accuracy: 0.8263\n",
      "Epoch 94/100, Loss: 0.5482, Train Accuracy: 0.8482, Test Accuracy: 0.8263\n",
      "Epoch 95/100, Loss: 0.5482, Train Accuracy: 0.8483, Test Accuracy: 0.8263\n",
      "Epoch 96/100, Loss: 0.5480, Train Accuracy: 0.8483, Test Accuracy: 0.8263\n",
      "Epoch 97/100, Loss: 0.5479, Train Accuracy: 0.8482, Test Accuracy: 0.8263\n",
      "Epoch 98/100, Loss: 0.5478, Train Accuracy: 0.8483, Test Accuracy: 0.8269\n",
      "Epoch 99/100, Loss: 0.5478, Train Accuracy: 0.8478, Test Accuracy: 0.8269\n",
      "Epoch 100/100, Loss: 0.5477, Train Accuracy: 0.8482, Test Accuracy: 0.8275\n",
      "Linear Train Accuracy 0.8482205386133571\n",
      "Linear Test Accuracy 0.8275418275418276\n"
     ]
    }
   ],
   "source": [
    "trainModel(linear_model, train_loader, linear_opt, loss_function)\n",
    "print(f\"Linear Train Accuracy {accuracy(linear_model, train_loader)}\")\n",
    "print(f\"Linear Test Accuracy {accuracy(linear_model, test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.6208, Train Accuracy: 0.6871, Test Accuracy: 0.6763\n",
      "Epoch 2/100, Loss: 1.0309, Train Accuracy: 0.7730, Test Accuracy: 0.7748\n",
      "Epoch 3/100, Loss: 0.7744, Train Accuracy: 0.8030, Test Accuracy: 0.8037\n",
      "Epoch 4/100, Loss: 0.6660, Train Accuracy: 0.8222, Test Accuracy: 0.8089\n",
      "Epoch 5/100, Loss: 0.6077, Train Accuracy: 0.8320, Test Accuracy: 0.8179\n",
      "Epoch 6/100, Loss: 0.5707, Train Accuracy: 0.8401, Test Accuracy: 0.8192\n",
      "Epoch 7/100, Loss: 0.5447, Train Accuracy: 0.8474, Test Accuracy: 0.8256\n",
      "Epoch 8/100, Loss: 0.5252, Train Accuracy: 0.8506, Test Accuracy: 0.8295\n",
      "Epoch 9/100, Loss: 0.5095, Train Accuracy: 0.8541, Test Accuracy: 0.8333\n",
      "Epoch 10/100, Loss: 0.4962, Train Accuracy: 0.8576, Test Accuracy: 0.8346\n",
      "Epoch 11/100, Loss: 0.4849, Train Accuracy: 0.8600, Test Accuracy: 0.8378\n",
      "Epoch 12/100, Loss: 0.4748, Train Accuracy: 0.8621, Test Accuracy: 0.8385\n",
      "Epoch 13/100, Loss: 0.4658, Train Accuracy: 0.8639, Test Accuracy: 0.8398\n",
      "Epoch 14/100, Loss: 0.4576, Train Accuracy: 0.8655, Test Accuracy: 0.8378\n",
      "Epoch 15/100, Loss: 0.4501, Train Accuracy: 0.8666, Test Accuracy: 0.8398\n",
      "Epoch 16/100, Loss: 0.4432, Train Accuracy: 0.8685, Test Accuracy: 0.8398\n",
      "Epoch 17/100, Loss: 0.4367, Train Accuracy: 0.8699, Test Accuracy: 0.8436\n",
      "Epoch 18/100, Loss: 0.4306, Train Accuracy: 0.8718, Test Accuracy: 0.8443\n",
      "Epoch 19/100, Loss: 0.4249, Train Accuracy: 0.8725, Test Accuracy: 0.8462\n",
      "Epoch 20/100, Loss: 0.4196, Train Accuracy: 0.8737, Test Accuracy: 0.8475\n",
      "Epoch 21/100, Loss: 0.4145, Train Accuracy: 0.8747, Test Accuracy: 0.8494\n",
      "Epoch 22/100, Loss: 0.4098, Train Accuracy: 0.8762, Test Accuracy: 0.8481\n",
      "Epoch 23/100, Loss: 0.4055, Train Accuracy: 0.8769, Test Accuracy: 0.8501\n",
      "Epoch 24/100, Loss: 0.4009, Train Accuracy: 0.8783, Test Accuracy: 0.8488\n",
      "Epoch 25/100, Loss: 0.3970, Train Accuracy: 0.8801, Test Accuracy: 0.8488\n",
      "Epoch 26/100, Loss: 0.3933, Train Accuracy: 0.8810, Test Accuracy: 0.8507\n",
      "Epoch 27/100, Loss: 0.3894, Train Accuracy: 0.8808, Test Accuracy: 0.8488\n",
      "Epoch 28/100, Loss: 0.3859, Train Accuracy: 0.8831, Test Accuracy: 0.8494\n",
      "Epoch 29/100, Loss: 0.3824, Train Accuracy: 0.8848, Test Accuracy: 0.8507\n",
      "Epoch 30/100, Loss: 0.3790, Train Accuracy: 0.8850, Test Accuracy: 0.8533\n",
      "Epoch 31/100, Loss: 0.3758, Train Accuracy: 0.8868, Test Accuracy: 0.8520\n",
      "Epoch 32/100, Loss: 0.3726, Train Accuracy: 0.8885, Test Accuracy: 0.8533\n",
      "Epoch 33/100, Loss: 0.3695, Train Accuracy: 0.8889, Test Accuracy: 0.8520\n",
      "Epoch 34/100, Loss: 0.3666, Train Accuracy: 0.8888, Test Accuracy: 0.8520\n",
      "Epoch 35/100, Loss: 0.3638, Train Accuracy: 0.8909, Test Accuracy: 0.8539\n",
      "Epoch 36/100, Loss: 0.3610, Train Accuracy: 0.8925, Test Accuracy: 0.8514\n",
      "Epoch 37/100, Loss: 0.3586, Train Accuracy: 0.8925, Test Accuracy: 0.8514\n",
      "Epoch 38/100, Loss: 0.3557, Train Accuracy: 0.8934, Test Accuracy: 0.8520\n",
      "Epoch 39/100, Loss: 0.3533, Train Accuracy: 0.8940, Test Accuracy: 0.8507\n",
      "Epoch 40/100, Loss: 0.3507, Train Accuracy: 0.8948, Test Accuracy: 0.8559\n",
      "Epoch 41/100, Loss: 0.3485, Train Accuracy: 0.8965, Test Accuracy: 0.8514\n",
      "Epoch 42/100, Loss: 0.3460, Train Accuracy: 0.8965, Test Accuracy: 0.8565\n",
      "Epoch 43/100, Loss: 0.3437, Train Accuracy: 0.8967, Test Accuracy: 0.8501\n",
      "Epoch 44/100, Loss: 0.3414, Train Accuracy: 0.8973, Test Accuracy: 0.8494\n",
      "Epoch 45/100, Loss: 0.3395, Train Accuracy: 0.8985, Test Accuracy: 0.8578\n",
      "Epoch 46/100, Loss: 0.3372, Train Accuracy: 0.8989, Test Accuracy: 0.8526\n",
      "Epoch 47/100, Loss: 0.3356, Train Accuracy: 0.9007, Test Accuracy: 0.8565\n",
      "Epoch 48/100, Loss: 0.3334, Train Accuracy: 0.9007, Test Accuracy: 0.8578\n",
      "Epoch 49/100, Loss: 0.3315, Train Accuracy: 0.9012, Test Accuracy: 0.8578\n",
      "Epoch 50/100, Loss: 0.3295, Train Accuracy: 0.9011, Test Accuracy: 0.8539\n",
      "Epoch 51/100, Loss: 0.3278, Train Accuracy: 0.9020, Test Accuracy: 0.8559\n",
      "Epoch 52/100, Loss: 0.3260, Train Accuracy: 0.9027, Test Accuracy: 0.8559\n",
      "Epoch 53/100, Loss: 0.3242, Train Accuracy: 0.9031, Test Accuracy: 0.8559\n",
      "Epoch 54/100, Loss: 0.3224, Train Accuracy: 0.9028, Test Accuracy: 0.8533\n",
      "Epoch 55/100, Loss: 0.3208, Train Accuracy: 0.9036, Test Accuracy: 0.8565\n",
      "Epoch 56/100, Loss: 0.3188, Train Accuracy: 0.9046, Test Accuracy: 0.8559\n",
      "Epoch 57/100, Loss: 0.3174, Train Accuracy: 0.9043, Test Accuracy: 0.8533\n",
      "Epoch 58/100, Loss: 0.3158, Train Accuracy: 0.9060, Test Accuracy: 0.8578\n",
      "Epoch 59/100, Loss: 0.3141, Train Accuracy: 0.9066, Test Accuracy: 0.8565\n",
      "Epoch 60/100, Loss: 0.3127, Train Accuracy: 0.9072, Test Accuracy: 0.8552\n",
      "Epoch 61/100, Loss: 0.3110, Train Accuracy: 0.9069, Test Accuracy: 0.8591\n",
      "Epoch 62/100, Loss: 0.3097, Train Accuracy: 0.9067, Test Accuracy: 0.8565\n",
      "Epoch 63/100, Loss: 0.3083, Train Accuracy: 0.9072, Test Accuracy: 0.8584\n",
      "Epoch 64/100, Loss: 0.3067, Train Accuracy: 0.9077, Test Accuracy: 0.8571\n",
      "Epoch 65/100, Loss: 0.3054, Train Accuracy: 0.9077, Test Accuracy: 0.8559\n",
      "Epoch 66/100, Loss: 0.3039, Train Accuracy: 0.9077, Test Accuracy: 0.8552\n",
      "Epoch 67/100, Loss: 0.3026, Train Accuracy: 0.9085, Test Accuracy: 0.8539\n",
      "Epoch 68/100, Loss: 0.3012, Train Accuracy: 0.9088, Test Accuracy: 0.8552\n",
      "Epoch 69/100, Loss: 0.2997, Train Accuracy: 0.9102, Test Accuracy: 0.8565\n",
      "Epoch 70/100, Loss: 0.2987, Train Accuracy: 0.9101, Test Accuracy: 0.8559\n",
      "Epoch 71/100, Loss: 0.2973, Train Accuracy: 0.9110, Test Accuracy: 0.8565\n",
      "Epoch 72/100, Loss: 0.2963, Train Accuracy: 0.9108, Test Accuracy: 0.8584\n",
      "Epoch 73/100, Loss: 0.2950, Train Accuracy: 0.9120, Test Accuracy: 0.8597\n",
      "Epoch 74/100, Loss: 0.2938, Train Accuracy: 0.9121, Test Accuracy: 0.8565\n",
      "Epoch 75/100, Loss: 0.2924, Train Accuracy: 0.9127, Test Accuracy: 0.8578\n",
      "Epoch 76/100, Loss: 0.2915, Train Accuracy: 0.9123, Test Accuracy: 0.8591\n",
      "Epoch 77/100, Loss: 0.2903, Train Accuracy: 0.9131, Test Accuracy: 0.8584\n",
      "Epoch 78/100, Loss: 0.2891, Train Accuracy: 0.9131, Test Accuracy: 0.8552\n",
      "Epoch 79/100, Loss: 0.2881, Train Accuracy: 0.9136, Test Accuracy: 0.8571\n",
      "Epoch 80/100, Loss: 0.2871, Train Accuracy: 0.9133, Test Accuracy: 0.8578\n",
      "Epoch 81/100, Loss: 0.2859, Train Accuracy: 0.9141, Test Accuracy: 0.8623\n",
      "Epoch 82/100, Loss: 0.2848, Train Accuracy: 0.9148, Test Accuracy: 0.8591\n",
      "Epoch 83/100, Loss: 0.2839, Train Accuracy: 0.9146, Test Accuracy: 0.8597\n",
      "Epoch 84/100, Loss: 0.2827, Train Accuracy: 0.9152, Test Accuracy: 0.8604\n",
      "Epoch 85/100, Loss: 0.2817, Train Accuracy: 0.9151, Test Accuracy: 0.8559\n",
      "Epoch 86/100, Loss: 0.2809, Train Accuracy: 0.9155, Test Accuracy: 0.8571\n",
      "Epoch 87/100, Loss: 0.2798, Train Accuracy: 0.9160, Test Accuracy: 0.8571\n",
      "Epoch 88/100, Loss: 0.2788, Train Accuracy: 0.9167, Test Accuracy: 0.8565\n",
      "Epoch 89/100, Loss: 0.2779, Train Accuracy: 0.9169, Test Accuracy: 0.8578\n",
      "Epoch 90/100, Loss: 0.2768, Train Accuracy: 0.9163, Test Accuracy: 0.8597\n",
      "Epoch 91/100, Loss: 0.2761, Train Accuracy: 0.9167, Test Accuracy: 0.8584\n",
      "Epoch 92/100, Loss: 0.2752, Train Accuracy: 0.9186, Test Accuracy: 0.8552\n",
      "Epoch 93/100, Loss: 0.2742, Train Accuracy: 0.9180, Test Accuracy: 0.8539\n",
      "Epoch 94/100, Loss: 0.2733, Train Accuracy: 0.9183, Test Accuracy: 0.8597\n",
      "Epoch 95/100, Loss: 0.2724, Train Accuracy: 0.9186, Test Accuracy: 0.8597\n",
      "Epoch 96/100, Loss: 0.2716, Train Accuracy: 0.9177, Test Accuracy: 0.8578\n",
      "Epoch 97/100, Loss: 0.2708, Train Accuracy: 0.9190, Test Accuracy: 0.8584\n",
      "Epoch 98/100, Loss: 0.2699, Train Accuracy: 0.9198, Test Accuracy: 0.8571\n",
      "Epoch 99/100, Loss: 0.2691, Train Accuracy: 0.9197, Test Accuracy: 0.8584\n",
      "Epoch 100/100, Loss: 0.2681, Train Accuracy: 0.9207, Test Accuracy: 0.8591\n",
      "MLP Train Accuracy 0.9206723117081556\n",
      "MLP Test Accuracy 0.859073359073359\n"
     ]
    }
   ],
   "source": [
    "trainModel(mlp_model, train_loader, mlp_opt, loss_function)\n",
    "print(f\"MLP Train Accuracy {accuracy(mlp_model, train_loader)}\")\n",
    "print(f\"MLP Test Accuracy {accuracy(mlp_model, test_loader)}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNabx6sCRInWIIstR96Z5ey",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
