{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 8.1 RNN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This week we will work up to creating an RNN text generator.  In today's lab you will implement a basic RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Complete the following implementation of an RNN.   Run the code to verify that the output shape is what it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.2503, -0.1016, -0.0992,  0.2633, -0.0647,  0.3171,  0.2099,  0.0213,\n",
      "         -0.0115, -0.1252, -0.0588, -0.0110,  0.1970,  0.0308, -0.0338, -0.0928,\n",
      "         -0.0127,  0.0281,  0.1548, -0.2935, -0.0357, -0.2845, -0.1808,  0.2179,\n",
      "          0.0213,  0.0094,  0.2204,  0.1602, -0.2544, -0.1285]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.4366,  0.0340, -0.0968,  0.4230, -0.0181,  0.5034,  0.2465,  0.0671,\n",
      "         -0.0491, -0.1636, -0.0323, -0.0025,  0.2926, -0.0217, -0.0595, -0.2426,\n",
      "         -0.0121,  0.1067,  0.2534, -0.2457, -0.0757, -0.3976, -0.1112,  0.1815,\n",
      "         -0.0734, -0.0389,  0.2630,  0.1854, -0.2486, -0.1834]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.5377,  0.2419, -0.1443,  0.5768,  0.0753,  0.4889,  0.2634, -0.0108,\n",
      "          0.0171, -0.1401, -0.0357, -0.2100,  0.1653,  0.0501, -0.0403, -0.0598,\n",
      "         -0.0109,  0.3006,  0.1555, -0.3163, -0.2710, -0.2651, -0.3323,  0.1629,\n",
      "         -0.1886, -0.0692,  0.2556,  0.0928, -0.0979, -0.1294]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-3.1896e-01,  7.6515e-02, -1.8122e-01,  4.7171e-01, -3.5689e-02,\n",
      "          4.1783e-01,  1.7553e-01,  1.8668e-02,  2.1119e-04, -7.7984e-02,\n",
      "         -9.5535e-02, -1.6274e-01,  7.4247e-02, -1.0247e-01, -1.8417e-02,\n",
      "         -6.5344e-02,  8.0807e-02,  1.1390e-01,  7.0034e-02, -3.4147e-01,\n",
      "         -1.0688e-01, -2.8754e-01, -3.2807e-01,  2.1688e-01, -6.9399e-02,\n",
      "         -5.5676e-02,  2.0092e-01,  2.1391e-01, -1.5812e-01, -8.4714e-02]],\n",
      "       grad_fn=<AddmmBackward0>), tensor([[-0.4804,  0.1629, -0.0396,  0.4281,  0.0414,  0.4243,  0.2493,  0.1281,\n",
      "         -0.0554, -0.1029, -0.0015, -0.1018,  0.2832, -0.0230, -0.0748, -0.2741,\n",
      "         -0.0233,  0.1822,  0.1249, -0.2927, -0.2749, -0.4010, -0.1230,  0.2163,\n",
      "          0.0452, -0.0496,  0.1158,  0.2451, -0.0679, -0.1740]],\n",
      "       grad_fn=<AddmmBackward0>)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size): \n",
    "      super().__init__() # inherits from torch.nn.Module\n",
    "      self.hidden_size = hidden_size\n",
    "      self.W = torch.nn.Linear(hidden_size, hidden_size) # next hidden states\n",
    "      self.U = torch.nn.Linear(input_size, hidden_size) # Input Weights\n",
    "      self.V = torch.nn.Linear(hidden_size, output_size) # Output Weights\n",
    "\n",
    "    def forward(self,x):\n",
    "       # x is a batch of embedding vector sequences of shape [B,N,C] where N is the sequence length, C is the input size\n",
    "       # forward pass should process the sequence and produce a sequence of N outputs\n",
    "       # output shape should be [B,N,O] where O is the output size\n",
    "      B, N, C = x.shape\n",
    "      h = torch.zeros(B, self.hidden_size, device=x.device) # initializes all of the hidden states to 0\n",
    "      outputs = []\n",
    "      for i in range(N):\n",
    "         valN = x[:, i, :] # input at i-th step for all batches\n",
    "         h = torch.relu(self.U(valN) + self.W(h)) # prdocues the next hidden state\n",
    "         y = self.V(h) # produces the output from the hidden state\n",
    "         outputs.append(y) \n",
    "\n",
    "      return torch.stack(outputs, dim=1)\n",
    "    \n",
    "  \n",
    "model = RNN(10,20,30)\n",
    "\n",
    "x = torch.rand(1,5,10)\n",
    "y = model(x)\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
