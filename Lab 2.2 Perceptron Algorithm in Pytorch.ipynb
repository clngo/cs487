{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 2.2: Perceptron Algorithm in PyTorch\n",
    "\n",
    "In this lab you will again implement the perceptron algorithm, but this time using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:06\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.1.0\n",
      "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch) (3.0.3)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /home/colin/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.12.0 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch is very similar to NumPy in its basic functionality.  In PyTorch arrays are called tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor(5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(6)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.zeros(3,5).float()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A note on broadcasting:* You may have noticed in the previous lab that NumPy is particular about the sizes of the arrays in operations; PyTorch is the same way.\n",
    "\n",
    "For example, if `A` has shape `(10,5)` and `b` has shape `(10,)`, then we can't compute `A*b`.  It wants the *last* dimensions to match, not the first ones.  So you would need to do either `A.T*b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.normal(size=(10,5))\n",
    "b = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operands could not be broadcast together with shapes (10,5) (10,) \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    A*b\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38847881, -0.5626746 ,  1.25907934,  0.64232121, -0.1277998 ,\n",
       "        -0.13425051, -0.07241136,  0.28927276, -1.45624085, -2.0434823 ],\n",
       "       [-1.07647421, -0.94679011, -0.64089027, -0.97784175, -1.10750976,\n",
       "        -0.56736301, -0.38424279, -0.41216369,  0.46051863, -0.63099655],\n",
       "       [ 0.56850151,  0.73189845,  1.397011  , -0.85433539,  0.88051217,\n",
       "         0.02515673, -1.31779655,  1.12472672, -0.46994546,  0.35280928],\n",
       "       [-0.3034394 ,  0.2922913 ,  1.59458565,  0.6403556 , -1.27600199,\n",
       "         1.58219226, -1.879448  ,  1.25675627, -0.86391803, -0.3213449 ],\n",
       "       [-1.17705543,  0.73517856, -0.03265319,  2.17832456, -1.67149913,\n",
       "         1.24812458,  0.64249916, -0.86899086, -0.8901553 ,  0.96526974]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.T*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to introduce an extra dimension of size one to $b$.  However, note that this produces the transposed result from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38847881, -1.07647421,  0.56850151, -0.3034394 , -1.17705543],\n",
       "       [-0.5626746 , -0.94679011,  0.73189845,  0.2922913 ,  0.73517856],\n",
       "       [ 1.25907934, -0.64089027,  1.397011  ,  1.59458565, -0.03265319],\n",
       "       [ 0.64232121, -0.97784175, -0.85433539,  0.6403556 ,  2.17832456],\n",
       "       [-0.1277998 , -1.10750976,  0.88051217, -1.27600199, -1.67149913],\n",
       "       [-0.13425051, -0.56736301,  0.02515673,  1.58219226,  1.24812458],\n",
       "       [-0.07241136, -0.38424279, -1.31779655, -1.879448  ,  0.64249916],\n",
       "       [ 0.28927276, -0.41216369,  1.12472672,  1.25675627, -0.86899086],\n",
       "       [-1.45624085,  0.46051863, -0.46994546, -0.86391803, -0.8901553 ],\n",
       "       [-2.0434823 , -0.63099655,  0.35280928, -0.3213449 ,  0.96526974]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*b[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38847881, -1.07647421,  0.56850151, -0.3034394 , -1.17705543],\n",
       "       [-0.5626746 , -0.94679011,  0.73189845,  0.2922913 ,  0.73517856],\n",
       "       [ 1.25907934, -0.64089027,  1.397011  ,  1.59458565, -0.03265319],\n",
       "       [ 0.64232121, -0.97784175, -0.85433539,  0.6403556 ,  2.17832456],\n",
       "       [-0.1277998 , -1.10750976,  0.88051217, -1.27600199, -1.67149913],\n",
       "       [-0.13425051, -0.56736301,  0.02515673,  1.58219226,  1.24812458],\n",
       "       [-0.07241136, -0.38424279, -1.31779655, -1.879448  ,  0.64249916],\n",
       "       [ 0.28927276, -0.41216369,  1.12472672,  1.25675627, -0.86899086],\n",
       "       [-1.45624085,  0.46051863, -0.46994546, -0.86391803, -0.8901553 ],\n",
       "       [-2.0434823 , -0.63099655,  0.35280928, -0.3213449 ,  0.96526974]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*np.expand_dims(b,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, carefully check the sizes of all arrays in your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we loading and format the Palmer penguins dataset for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_penguins()\n",
    "\n",
    "# drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# tricky code to randomly shuffle the rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# select only two specices\n",
    "df = df[(df['species']=='Adelie')|(df['species']=='Chinstrap')]\n",
    "\n",
    "# get two features\n",
    "X = df[['flipper_length_mm','bill_length_mm']].values\n",
    "\n",
    "# convert speces labels to -1 and 1\n",
    "y = df['species'].map({'Adelie':-1,'Chinstrap':1}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
    "\n",
    "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X -= np.mean(X,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert our `X` and `y` arrays to torch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "Your task is to again complete this class for the perceptron, with two changes from last time:\n",
    "- the implementation should use PyTorch tensors, not NumPy arrays;\n",
    "- `train_step` now accepts the entire dataset as input and should calculate the average gradient over all examples, rather than updating the weights one data point at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self,lr=1e-3):\n",
    "        # store the learning rate\n",
    "        self.lr = lr\n",
    "\n",
    "        # initialize the weights to small, normally-distributed values\n",
    "        self.w = torch.normal(mean=0, std=0.01, size=(2,))\n",
    "\n",
    "        # initialize the bias to zero\n",
    "        self.b = torch.zeros(1)\n",
    "\n",
    "    def train_step(self,X:torch.Tensor,y:torch.Tensor) -> None:\n",
    "        \"\"\" Apply the first update rule shown in lecture.\n",
    "            Arguments:\n",
    "             x: data matrix of shape (N,3)\n",
    "             y: labels of shape (N,) \n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        # update rule: w' = w + syx\n",
    "        z = X @ self.w + self.b\n",
    "        \n",
    "        misclassified = y * z <= 0\n",
    "        \n",
    "        self.w += self.lr * torch.sum(misclassified.unsqueeze(1) * y.unsqueeze(1) * X, dim=0)\n",
    "        self.b += self.lr * torch.sum(misclassified * y)\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self,X:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model prediction for all data points.\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "            Returns:\n",
    "             Predicted labels (-1 or 1) of shape (N,)\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        z = X @ self.w + self.b  \n",
    "        return torch.where(z>0,1,-1)\n",
    "    \n",
    "    def score(self,X:torch.Tensor,y:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\" Calculate model accuracy\n",
    "            Arguments:\n",
    "             X: data matrix of shape (N,3)   \n",
    "             y: labels of shape (N,)\n",
    "            Returns:\n",
    "             Accuracy score\n",
    "        \"\"\"\n",
    "        # WRITE CODE HERE\n",
    "        pred = self.predict(X)\n",
    "        return torch.mean((pred == y).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to train the model and print out the accuracy at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: 0.6915887594223022\n",
      "step 1: 0.6168224215507507\n",
      "step 2: 0.7850467562675476\n",
      "step 3: 0.855140209197998\n",
      "step 4: 0.9345794320106506\n",
      "step 5: 0.9392523169517517\n",
      "step 6: 0.9252336621284485\n",
      "step 7: 0.9345794320106506\n",
      "step 8: 0.9345794320106506\n",
      "step 9: 0.9392523169517517\n",
      "step 10: 0.9439252614974976\n",
      "step 11: 0.9439252614974976\n",
      "step 12: 0.9485981464385986\n",
      "step 13: 0.9439252614974976\n",
      "step 14: 0.9485981464385986\n",
      "step 15: 0.9485981464385986\n",
      "step 16: 0.9485981464385986\n",
      "step 17: 0.9532710313796997\n",
      "step 18: 0.9626168012619019\n",
      "step 19: 0.9626168012619019\n",
      "step 20: 0.9626168012619019\n",
      "step 21: 0.9626168012619019\n",
      "step 22: 0.9532710313796997\n",
      "step 23: 0.9532710313796997\n",
      "step 24: 0.9532710313796997\n",
      "step 25: 0.9579439163208008\n",
      "step 26: 0.9579439163208008\n",
      "step 27: 0.9672897458076477\n",
      "step 28: 0.9579439163208008\n",
      "step 29: 0.9626168012619019\n",
      "step 30: 0.9626168012619019\n",
      "step 31: 0.9626168012619019\n",
      "step 32: 0.9626168012619019\n",
      "step 33: 0.9626168012619019\n",
      "step 34: 0.9579439163208008\n",
      "step 35: 0.9579439163208008\n",
      "step 36: 0.9532710313796997\n",
      "step 37: 0.9579439163208008\n",
      "step 38: 0.9392523169517517\n",
      "step 39: 0.9299065470695496\n",
      "step 40: 0.8084112405776978\n",
      "step 41: 0.7850467562675476\n",
      "step 42: 0.8925233483314514\n",
      "step 43: 0.9205607771873474\n",
      "step 44: 0.8971962332725525\n",
      "step 45: 0.9392523169517517\n",
      "step 46: 0.9392523169517517\n",
      "step 47: 0.9672897458076477\n",
      "step 48: 0.9579439163208008\n",
      "step 49: 0.9579439163208008\n",
      "step 50: 0.9579439163208008\n",
      "step 51: 0.9626168012619019\n",
      "step 52: 0.9626168012619019\n",
      "step 53: 0.9626168012619019\n",
      "step 54: 0.9626168012619019\n",
      "step 55: 0.9626168012619019\n",
      "step 56: 0.9626168012619019\n",
      "step 57: 0.9579439163208008\n",
      "step 58: 0.9579439163208008\n",
      "step 59: 0.9532710313796997\n",
      "step 60: 0.9532710313796997\n",
      "step 61: 0.9532710313796997\n",
      "step 62: 0.9532710313796997\n",
      "step 63: 0.9345794320106506\n",
      "step 64: 0.8971962332725525\n",
      "step 65: 0.8084112405776978\n",
      "step 66: 0.7850467562675476\n",
      "step 67: 0.9252336621284485\n",
      "step 68: 0.9532710313796997\n",
      "step 69: 0.9626168012619019\n",
      "step 70: 0.9579439163208008\n",
      "step 71: 0.9579439163208008\n",
      "step 72: 0.9579439163208008\n",
      "step 73: 0.9579439163208008\n",
      "step 74: 0.9626168012619019\n",
      "step 75: 0.9626168012619019\n",
      "step 76: 0.9626168012619019\n",
      "step 77: 0.9626168012619019\n",
      "step 78: 0.9626168012619019\n",
      "step 79: 0.9626168012619019\n",
      "step 80: 0.9626168012619019\n",
      "step 81: 0.9579439163208008\n",
      "step 82: 0.9626168012619019\n",
      "step 83: 0.9579439163208008\n",
      "step 84: 0.9532710313796997\n",
      "step 85: 0.9439252614974976\n",
      "step 86: 0.9485981464385986\n",
      "step 87: 0.9579439163208008\n",
      "step 88: 0.9532710313796997\n",
      "step 89: 0.9532710313796997\n",
      "step 90: 0.9439252614974976\n",
      "step 91: 0.9532710313796997\n",
      "step 92: 0.9485981464385986\n",
      "step 93: 0.9579439163208008\n",
      "step 94: 0.9439252614974976\n",
      "step 95: 0.9485981464385986\n",
      "step 96: 0.9439252614974976\n",
      "step 97: 0.9485981464385986\n",
      "step 98: 0.9439252614974976\n",
      "step 99: 0.9532710313796997\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "model = Perceptron(lr)\n",
    "for i in range(epochs):\n",
    "    model.train_step(X,y)\n",
    "    print(f'step {i}: {model.score(X,y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training multiple times.  Is the training the same each time, or does it vary?  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training results vary because of random intialization of weights, but it is around "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the learning rate and number of epochs to find the best setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
